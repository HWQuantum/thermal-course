# Lab 1 — Entropy Mixing

---

# Thermal Physics Lab 1 — Entropy Increase Due to Convection and Conduction

**Physics, Heriot-Watt University**

---

## Overview

In this lab, we will create a simulation designed to illustrate the concept of entropy increase through either convection or conduction.

The simulation shows how a system with several hot particles separated from cold particles evolves as the particles mix and exchange energy.

We initialise an array of $N$ particles with hot particles separated from cold particles. As time evolves, neighbouring particles can either:

- Swap positions (convection), or  
- Exchange/average their energies (conduction).

We find that the entropy increases with time, reflecting a loss of spatial information about where the hot particles are.

This is an illustration of the **second law of thermodynamics**, which states that the entropy of a closed system will increase or remain constant with time.

---

## Learning Outcomes

By the end of this lab you should be able to:

- Simulate convection and/or conduction of heat via simple update rules.
- Describe entropy as a measure of spatial distribution of energy.
- Understand that small fluctuations can temporarily reduce entropy.
- Explain how microscopic randomness produces predictable macroscopic behaviour.

---

# Background

## Shannon Entropy

The Shannon entropy is

$$
S = -\sum_i p_i \log_2 p_i
$$

where $p_i$ is the probability of a random event occurring.

Using $\log_2$ gives entropy in **bits**.

---

## Gibbs and Boltzmann Entropy

In statistical mechanics,

$$
S = -k_B \sum_i p_i \ln p_i
$$

If all microstates are equally probable, $p_i = 1/\Omega$, giving

$$
S = k_B \ln \Omega.
$$

If $\Omega = 1$, then $S = 0$.

---

## Second Law of Thermodynamics

For an isolated system,

$$
\Delta S_{\text{total}} \ge 0.
$$

Entropy increases until equilibrium is reached.

---

## Convection vs Conduction

- **Convection** → swap neighbouring particles.
- **Conduction** → average neighbouring energies.

---

# Simulation Details

```{figure} ../assets/images/Entropy.pdf
:width: 90%

Schematic illustration of entropy increase during mixing.
