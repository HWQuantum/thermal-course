{"version":"1","records":[{"hierarchy":{"lvl1":"Thermal Physics Simulations"},"type":"lvl1","url":"/","position":0},{"hierarchy":{"lvl1":"Thermal Physics Simulations"},"content":"Welcome to the course site.  This course will investigate several concepts in thermal physics and use different numerical techniques to solve complicated problems.  The course is based around four labs.  These are simulating entropy increases via convection and conduction; solving the heat diffusion equation via the finite-differnce method; solving the heat diffusion equation using Fourier transforms; and simulating the temperature dependence of magnetism via the Ising model.\n\nThe numerical methods that we will be using include Monte Carlo methods, finite-differnce methods, and Fourier-based methods.  While we use these methods to solve problems in thermal physics, they are general techniques that are used across many areas of physics and engineering.\n\nLab 1 — Entropy Mixing\n\nSimulate entropy increase using convection and conduction.\n\nLab 2 — The Heat Diffusion Equation - Finite Difference Method\n\nSolving the heat diffusion using the finite difference method.\n\nLab 3 - The Heat Diffusion Equation - Fourier Transform Method\n\nSolving the heat diffusion equation using the Fourier transform method.\n\nLab 4 - Ising Model\n\nThe Ising model for magnetism.","type":"content","url":"/","position":1},{"hierarchy":{"lvl1":"Lab 1 - Entropy Increase"},"type":"lvl1","url":"/lab1","position":0},{"hierarchy":{"lvl1":"Lab 1 - Entropy Increase"},"content":"","type":"content","url":"/lab1","position":1},{"hierarchy":{"lvl1":"Lab 1 - Entropy Increase","lvl2":"Overview"},"type":"lvl2","url":"/lab1#overview","position":2},{"hierarchy":{"lvl1":"Lab 1 - Entropy Increase","lvl2":"Overview"},"content":"In this lab, we will create a simulation designed to illustrate the concept of entropy increase through either convection or conduction. The simulation will show how a system with several hot particles separated from cold particles evolves as the particles mix and exchange energy.  We will start by initialising an array of N particles with the hot particles originally separated from the cold particles.  As time evolves, neighbouring particles can either swap positions, representing convection, or they can exchange energy, representing conduction.  We find that the entropy increases with time, reflecting a loss of spatial information about where the hot particles are.  This is an example of the second law of thermodynamics, which states that the entropy of a closed system will increase or remain constant with time.\n\nThis simulation is an example of predictable macroscopic behaviour emerging from simple rules of microscopic states.  We can make some simple assumptions about how two neighbouring particles might interact with each other, and then observe how these influence the properties of the combined system.\n\nIn this case, we the only update rule that we apply is that neighbouring particles can either swap locations (simulating convection) or exchange and average their energies (simulating conduction).  These simple rules then result in a predictable increase in entropy associated with the location of the heat in a system.  An important outcome is that we can be confident of the long-term behaviour of the system (increase in entropy), but we cannot predict what will happen in any one time step (the entropy may go up or down).","type":"content","url":"/lab1#overview","position":3},{"hierarchy":{"lvl1":"Lab 1 - Entropy Increase","lvl3":"How will you be assessed?","lvl2":"Overview"},"type":"lvl3","url":"/lab1#how-will-you-be-assessed","position":4},{"hierarchy":{"lvl1":"Lab 1 - Entropy Increase","lvl3":"How will you be assessed?","lvl2":"Overview"},"content":"At the end of the lab, you will hand in a single MATLAB .m file that contains your simulation and generates your results.  You should comment your code throughout, so that it is clear that you understand the physics and the results.  Make sure that all plots and graphs have suitable axes and labels.\n\nIn order to pass this lab, your code must run and generate results in line with the learning objectives below. This is a pass/fail lab, so you will be given 100% if your code meets the minimum requirements, and 0% if you do not.\n\nIn addition to the baseline results, you are expected to try some of the “Further Investigation,\" detailed at the end.","type":"content","url":"/lab1#how-will-you-be-assessed","position":5},{"hierarchy":{"lvl1":"Lab 1 - Entropy Increase","lvl3":"Learning Outcomes","lvl2":"Overview"},"type":"lvl3","url":"/lab1#learning-outcomes","position":6},{"hierarchy":{"lvl1":"Lab 1 - Entropy Increase","lvl3":"Learning Outcomes","lvl2":"Overview"},"content":"The objectives of this lab are to:\n\nHow to simulate convection and/or conduction of heat via simple update rules.\n\nDescribe entropy as a measure of the spatial distribution of energy.\n\nUnderstand that small fluctuations can lead to a decrease in entropy, but the second law governs the global behaviour as time increases.\n\nExplore how microscopic random motion relates to macroscopic thermodynamic behaviour.","type":"content","url":"/lab1#learning-outcomes","position":7},{"hierarchy":{"lvl1":"Lab 1 - Entropy Increase","lvl2":"Background"},"type":"lvl2","url":"/lab1#background","position":8},{"hierarchy":{"lvl1":"Lab 1 - Entropy Increase","lvl2":"Background"},"content":"","type":"content","url":"/lab1#background","position":9},{"hierarchy":{"lvl1":"Lab 1 - Entropy Increase","lvl3":"Shannon entropy","lvl2":"Background"},"type":"lvl3","url":"/lab1#shannon-entropy","position":10},{"hierarchy":{"lvl1":"Lab 1 - Entropy Increase","lvl3":"Shannon entropy","lvl2":"Background"},"content":"The Shannon entropy S is given byS = -\\sum_{i} p_i \\log_2 p_i,\n\nwhere p_i is the probability of a random event occurring.  The Shannon entropy is dimensionless as it is based on probabilities, and the units depend on the base of the logarithm.  In this case, we are using \\log_2, so the units of S are bits.","type":"content","url":"/lab1#shannon-entropy","position":11},{"hierarchy":{"lvl1":"Lab 1 - Entropy Increase","lvl3":"Gibbs and Boltzmann’s entropy","lvl2":"Background"},"type":"lvl3","url":"/lab1#gibbs-and-boltzmanns-entropy","position":12},{"hierarchy":{"lvl1":"Lab 1 - Entropy Increase","lvl3":"Gibbs and Boltzmann’s entropy","lvl2":"Background"},"content":"In statistical mechanics, the Gibbs entropy is defined asS = -k_B \\sum_{i} p_i \\ln p_i\n\nwhere p_i is the probability of the system being in microstate i, and k_B is Boltzmann’s constant.  The Gibbs entropy has units of Joules per Kelvin J K^{-1}, which comes from Boltzmann’s constant k_B.\n\nIf all microstates are equally probable, then we have p_i = 1 / \\Omega, where \\Omega is the total number of states.  If we insert this probability in the Gibbs entropy, we obtain the common Boltzmann form of entropyS = -k_B \\sum_{i} \\frac{1}{\\Omega} \\ln\\frac{1}{\\Omega} = k_B \\ln \\Omega.\n\nWe see that if there is only one possible microstate, then the entropy is given by S=k_B\\ln 1=0~J K^{-1}, as is equal to zero.","type":"content","url":"/lab1#gibbs-and-boltzmanns-entropy","position":13},{"hierarchy":{"lvl1":"Lab 1 - Entropy Increase","lvl3":"Second law of thermodynamics","lvl2":"Background"},"type":"lvl3","url":"/lab1#second-law-of-thermodynamics","position":14},{"hierarchy":{"lvl1":"Lab 1 - Entropy Increase","lvl3":"Second law of thermodynamics","lvl2":"Background"},"content":"In any isolated system, the total entropy can never decrease over time. It either increases or stays the same, reaching a maximum at equilibrium.  Entropy is a measure of how many microstates correspond to a given macrostate (how disordered or probable the system is).  The second law states that\\Delta S_{\\text{total}} \\ge 0,\n\nwhere \\Delta S_{\\text{total}} is the change in entropy of the entire system.","type":"content","url":"/lab1#second-law-of-thermodynamics","position":15},{"hierarchy":{"lvl1":"Lab 1 - Entropy Increase","lvl3":"Convection and conduction","lvl2":"Background"},"type":"lvl3","url":"/lab1#convection-and-conduction","position":16},{"hierarchy":{"lvl1":"Lab 1 - Entropy Increase","lvl3":"Convection and conduction","lvl2":"Background"},"content":"Convection is the transfer of heat by the movement of molecules within a liquid or gas.  Hot regions become of liquid or gas have a low density, while cooler regions are denser.  This results in a flow of particles that moves heat. We will simulate convection by swapping the location of two adjacent particles.\n\nConduction is the transfer of heat through a material without the movement of the material itself.  This happens when faster-moving (hotter) particles collide with slower ones, passing on energy.  We will simulate conduction by the averaging of the heat energies of two adjacent particles.","type":"content","url":"/lab1#convection-and-conduction","position":17},{"hierarchy":{"lvl1":"Lab 1 - Entropy Increase","lvl2":"Simulation details"},"type":"lvl2","url":"/lab1#simulation-details","position":18},{"hierarchy":{"lvl1":"Lab 1 - Entropy Increase","lvl2":"Simulation details"},"content":"We start by initialising the system, then letting the system evolve according to the physics rules we have established (convection or conduction).  We then calculate properties associated with the system, e.g. the Gibbs entropy associated with the temperature distribution, and then plot and analyse the results.  Strictly, the Gibbs entropy uses the microstates of a system, but it is often not possible to know or count all of the microstates of a system.  In such a case, we can use a coarse-grained version where we calculate the fraction of total energy (or hot particle content) in spatial region i.\n\nTo achieve this, we will divide the total system into several (2 or 4) regions, and calculate the probability of finding a hot particle in each region.  We always require a probability distribution to calculate entropy, and we will use the probability distribution of heat in this simulation in the Gibbs formulation.  The heat probability distribution provides the necessary information about “where the heat is in the system,” which is what is needed to calculate the entropy.","type":"content","url":"/lab1#simulation-details","position":19},{"hierarchy":{"lvl1":"Lab 1 - Entropy Increase","lvl2":"Physical Interpretation"},"type":"lvl2","url":"/lab1#physical-interpretation","position":20},{"hierarchy":{"lvl1":"Lab 1 - Entropy Increase","lvl2":"Physical Interpretation"},"content":"\n\nFigure 1:Schematic illustration of the simulation.  We start with an initial distribution of cold particles on the left and hot particles on the right.  The probability distribution measures where we find the hot particles.  At t = 0, these are all on the right-hand side, and this corresponds to an entropy of 0 bits.  As t increases, we update the distribution and calculate S_t.   After many iterations, the entropy will tend to the maximum value, S_{t>10^6} \\approx k_B \\ln 2 = 0.69~k_B.\n\nFor a system with distinguishable regions and energy distribution, entropy can be related to our ability to localize energy (e.g., hot particles). The entropy measures the distribution of this energy throughout the system\n\nAt the start of this simulation, all hot particles are on the right and all cold particles on the left, therefore, the system is highly ordered and low in entropy. As particles move and mix, it becomes increasingly difficult to determine where the hot particles are, indicating an increase in entropy. As particles swap places and energy becomes more uniformly distributed, the number of possible microstates increases, and so too does the entropy.\n\nThis is exactly what is contained in the second law of thermodynamics, which states that in an isolated system, entropy tends to increase with time. In our simulation, there is no energy input or output, and yet the system evolves from a low-entropy state (localized energy) to a high-entropy state (spread-out energy). The entropy increase is a direct result of this spatial delocalization.","type":"content","url":"/lab1#physical-interpretation","position":21},{"hierarchy":{"lvl1":"Lab 1 - Entropy Increase","lvl2":"Pseudo Code"},"type":"lvl2","url":"/lab1#pseudo-code","position":22},{"hierarchy":{"lvl1":"Lab 1 - Entropy Increase","lvl2":"Pseudo Code"},"content":"Algorithm\n\nEntropy Mixing Simulation (1D)\n\nInitialisation\n\nInitialise a vector v of length N (e.g 100) with values 0 on the left for cold and 1 on the right for hot.\n\nSet the total number of time steps T (e.g. 10,000), set the number of bins B for entropy calculation (e.g. 2, 4, or 8), and initialise a vector of length T to store entropy values S.  Below, we have B=2.\n\nFor each time step t from 1 to T:\n\nRandomly choose an index i in 1,\\dots,N\n\nIf i = 1: set neighbour index j = 2Else if i = N: set neighbour index j = N-1Else: randomly choose j = i - 1 or j = i + 1\n\nSwap the values to simulate convection (v[i] \\leftrightarrow v[j])\n\nCompute the probability distribution of heat P\n\nDivide v into two equal spatial bins b= \\{1,2\\}\n\nFor each bin b:p_b = (\\text{sum of values in bin } b) / (\\text{sum of all values})\n\nCompute entropy at time step t:S_t = -k_B \\sum_{b=1}^{2} p_b \\ln p_b\n\nStore S_t in entropy array\n\nPlot v_t, P, and S_t every 100 iterations","type":"content","url":"/lab1#pseudo-code","position":23},{"hierarchy":{"lvl1":"Lab 1 - Entropy Increase","lvl2":"Target Results"},"type":"lvl2","url":"/lab1#target-results","position":24},{"hierarchy":{"lvl1":"Lab 1 - Entropy Increase","lvl2":"Target Results"},"content":"\n\nFigure 2:Target results.","type":"content","url":"/lab1#target-results","position":25},{"hierarchy":{"lvl1":"Lab 1 - Entropy Increase","lvl2":"Further investigation"},"type":"lvl2","url":"/lab1#further-investigation","position":26},{"hierarchy":{"lvl1":"Lab 1 - Entropy Increase","lvl2":"Further investigation"},"content":"Here are some suggestions for further development of the simulation:\n\nDifferent initial conditions: Try starting with alternating hot and cold particles or a Gaussian heat profile.\n\nSimulation of conduction: Replace the swapping of the particles at each iteration with averaging.  This would represent conduction rather than convection.\n\nTrack mean hot particle position: Track and plot the mean position of hot particles over time.\n\n2D extension: Extend the system to a 2D lattice and observe entropy changes as particles diffuse in two dimensions.","type":"content","url":"/lab1#further-investigation","position":27},{"hierarchy":{"lvl1":"Lab 2 - The Heat Diffusion Equation - Finite Difference"},"type":"lvl1","url":"/lab2","position":0},{"hierarchy":{"lvl1":"Lab 2 - The Heat Diffusion Equation - Finite Difference"},"content":"","type":"content","url":"/lab2","position":1},{"hierarchy":{"lvl1":"Lab 2 - The Heat Diffusion Equation - Finite Difference","lvl2":"Overview"},"type":"lvl2","url":"/lab2#overview","position":2},{"hierarchy":{"lvl1":"Lab 2 - The Heat Diffusion Equation - Finite Difference","lvl2":"Overview"},"content":"In this lab, we will solve the heat diffusion equation, representing the conduction of heat through a solid as time evolves. The simulation will show how a system with an initial localised area of heat will transition to a system where the heat is distributed throughout space.  We will start by initialising an array that represents where the heat in a sample is and then use the finite-difference method to solve the equation and update the spatial distribution of heat as time evolves.  We find that the heat distribution at time t+\\Delta t is equal to the current heat distribution plus a constant times the curvature of the distribution.  That is to say that areas of sharp peaks or valleys in temperature will change the fastest as these are the areas with the highest spatial curvatures. The curvature is measured by numerically calculating the second-order derivative of temperature with respect to space.\n\nThis simulation is an example of using a finite difference approach for solving a second-order partial differential equation.  A very similar approach can be used to solve many other similar differential equations.  Two examples are the wave equation for simulating light or sound propagation, and the Schr\\ddot{\\text{o}}dinger equation for simulating wave function evolution in quantum mechanics.  There are special requirements in each case that are needed to ensure the stability of the solutions.  In this case, we can ensure stability through the Courant–Friedrichs–Lewy (CFL) condition, which relates the time step size to the discretisation in space.","type":"content","url":"/lab2#overview","position":3},{"hierarchy":{"lvl1":"Lab 2 - The Heat Diffusion Equation - Finite Difference","lvl3":"How will you be assessed?","lvl2":"Overview"},"type":"lvl3","url":"/lab2#how-will-you-be-assessed","position":4},{"hierarchy":{"lvl1":"Lab 2 - The Heat Diffusion Equation - Finite Difference","lvl3":"How will you be assessed?","lvl2":"Overview"},"content":"At the end of the lab, you will submit a single MATLAB .m file that performs the simulation and generates the required plots. Your code should be clearly commented to demonstrate understanding of the numerical method and the underlying physics.\n\nIn order to pass this lab, your code must:\n\nCorrectly implement the finite difference method\n\nProduce physically reasonable results\n\nInclude appropriate plots with labelled axes\n\nThis is a pass/fail lab.","type":"content","url":"/lab2#how-will-you-be-assessed","position":5},{"hierarchy":{"lvl1":"Lab 2 - The Heat Diffusion Equation - Finite Difference","lvl3":"Learning Outcomes","lvl2":"Overview"},"type":"lvl3","url":"/lab2#learning-outcomes","position":6},{"hierarchy":{"lvl1":"Lab 2 - The Heat Diffusion Equation - Finite Difference","lvl3":"Learning Outcomes","lvl2":"Overview"},"content":"The objectives of this lab are to:\n\nUnderstand the one-dimensional heat equation.\n\nImplement a finite difference approximation.\n\nExplore numerical stability conditions.\n\nInterpret the physical meaning of diffusion.","type":"content","url":"/lab2#learning-outcomes","position":7},{"hierarchy":{"lvl1":"Lab 2 - The Heat Diffusion Equation - Finite Difference","lvl2":"Background"},"type":"lvl2","url":"/lab2#background","position":8},{"hierarchy":{"lvl1":"Lab 2 - The Heat Diffusion Equation - Finite Difference","lvl2":"Background"},"content":"\n\nFigure 2:The problem that we will solve is given an initial spatial temperature distribution at time = 0, what is the temperature distribution at time = t?","type":"content","url":"/lab2#background","position":9},{"hierarchy":{"lvl1":"Lab 2 - The Heat Diffusion Equation - Finite Difference","lvl3":"One dimensional diffusion equation","lvl2":"Background"},"type":"lvl3","url":"/lab2#one-dimensional-diffusion-equation","position":10},{"hierarchy":{"lvl1":"Lab 2 - The Heat Diffusion Equation - Finite Difference","lvl3":"One dimensional diffusion equation","lvl2":"Background"},"content":"The heat diffusion equation (or simply, the heat equation) describes how heat flows in a medium over time. In one dimension, it is given by:\\begin{align}\n\\frac{\\partial T(x,t)}{\\partial t} = \\alpha \\frac{\\partial^2 T(x,t)}{\\partial x^2}\n\\end{align}\n\nwhere T(x,t) is the temperature at position x and time t, and \\alpha is the thermal diffusivity.  This equation assumes that we have a constant thermal diffusivity \\alpha, there are no internal heat source, and this for the one-dimensional case (e.g. a rod).  Simple modifications of the equation can introduce additional features, such as internal sources of heat, and the same concepts are applied when solving the equation in 2 and 3 dimensions.","type":"content","url":"/lab2#one-dimensional-diffusion-equation","position":11},{"hierarchy":{"lvl1":"Lab 2 - The Heat Diffusion Equation - Finite Difference","lvl3":"Two dimensional diffusion equation","lvl2":"Background"},"type":"lvl3","url":"/lab2#two-dimensional-diffusion-equation","position":12},{"hierarchy":{"lvl1":"Lab 2 - The Heat Diffusion Equation - Finite Difference","lvl3":"Two dimensional diffusion equation","lvl2":"Background"},"content":"The two-dimensional diffusion equation is given by\\begin{align}\n\\frac{\\partial T(x, y, t)}{\\partial t} = \\alpha \\left( \\frac{\\partial^2 T}{\\partial x^2} + \\frac{\\partial^2 T}{\\partial y^2} \\right) = \\alpha \\nabla^2 T.\n\\end{align}","type":"content","url":"/lab2#two-dimensional-diffusion-equation","position":13},{"hierarchy":{"lvl1":"Lab 2 - The Heat Diffusion Equation - Finite Difference","lvl3":"Finite Difference Approximation","lvl2":"Background"},"type":"lvl3","url":"/lab2#finite-difference-approximation","position":14},{"hierarchy":{"lvl1":"Lab 2 - The Heat Diffusion Equation - Finite Difference","lvl3":"Finite Difference Approximation","lvl2":"Background"},"content":"\n\nFigure 2:The heat diffusion equation is solved by taking the current distribution given by T(x, t) and adding \\alpha times the curvature in space times \\Delta t.\n\nTo find a numerical solution, we discretize the heat equation using the finite-difference method. If we discretize time in to steps of size \\Delta t and leave space continuous, we see that\\begin{align}\n\\frac{\\partial T(x,t)}{\\partial t} \\approx \\frac{T(x, t+\\Delta t)-T(x, t)}{\\Delta t} & =  \\alpha \\frac{\\partial^2 T(x, t)}{\\partial x^2} ,\\\\\n\\rightarrow T(x, t+\\Delta t) & = T(x, t) +\\alpha \\frac{\\partial^2 T(x, t)}{\\partial x^2} \\Delta t,\n\\end{align}\n\nwhich, in words, means that the temperature distribution T(x) at time t + \\Delta t  is equal to the current temperature distribution plus \\alpha times the curvature in space times \\Delta t.  We can then define a grid with spatial steps \\Delta x, so that the numerically evaluated curvature is equal to\\begin{align}\n\\frac{\\partial^2 T(x,t)}{\\partial x^2} \\approx \\frac{\\frac{  T({x+1},t) - T(x,t)}{\\Delta x}-\\frac{  T(x,t) - T(x-1,t)}{\\Delta x}}{\\Delta x} =  \\frac{  T({x+1},t) - 2T(x,t) + T(x-1,t) }{(\\Delta x)^2}\n\\end{align}\n\nA visual guide to equation \\ref{solution} is given in figure \\ref{derivatives}.  This means that the discrete version of the equation becomes:\\begin{align}\nT(x,{t+\\Delta t}) = T(x, t) + \\alpha \\frac{   T({x+1},t) - 2T(x,t) + T(x-1,t) }{(\\Delta x)^2} \\Delta t.\n\\end{align}\n\nThis is often written as\\begin{align}\nT_i^{n+1} = T_i^n + \\alpha \\frac{\\Delta t}{(\\Delta x)^2} \\left( T_{i+1}^n - 2T_i^n + T_{i-1}^n \\right),\n\\end{align}\n\nwhere the x spatial position is replaced with the index i, and the time t is replaced with the temopral index n.  This is useful when using a computer to solve the equation numerically.\n\n\n\nFigure 3:Visual aid for how the numerical gradient and curvature of a function are calculated numerically.  The gradient is the difference between the function’s values on either side of the point of interest divided by 2 \\Delta x.  The curvature is the difference in the gradient on either side of the point of interest divided by \\Delta x.","type":"content","url":"/lab2#finite-difference-approximation","position":15},{"hierarchy":{"lvl1":"Lab 2 - The Heat Diffusion Equation - Finite Difference","lvl3":"Stability Condition","lvl2":"Background"},"type":"lvl3","url":"/lab2#stability-condition","position":16},{"hierarchy":{"lvl1":"Lab 2 - The Heat Diffusion Equation - Finite Difference","lvl3":"Stability Condition","lvl2":"Background"},"content":"In many numerical approaches to solving partial differential equations, there are conditions that are required for stability of the solution. For stability in this case, we need to ensure that the Courant–Friedrichs–Lewy (CFL) condition is satisfied.  This places a limit on the size of \\alpha \\Delta t compared to (\\Delta x)^2 according to\\begin{align}\n\\frac{\\alpha \\Delta t}{(\\Delta x)^2} \\leq \\frac{1}{2}.\n\\end{align}\n\nIf this condition is not met, you will find that the numerical solution becomes unstable.","type":"content","url":"/lab2#stability-condition","position":17},{"hierarchy":{"lvl1":"Lab 2 - The Heat Diffusion Equation - Finite Difference","lvl3":"Extension to two dimensions","lvl2":"Background"},"type":"lvl3","url":"/lab2#extension-to-two-dimensions","position":18},{"hierarchy":{"lvl1":"Lab 2 - The Heat Diffusion Equation - Finite Difference","lvl3":"Extension to two dimensions","lvl2":"Background"},"content":"We can extend the simulation to represent diffusion in two dimensions.  On a grid with spacing \\Delta x = \\Delta y = h, and time step \\Delta t, the finite difference update is given by\\begin{align}\nT_{i,j}^{n+1} = T_{i,j}^n + \\frac{\\alpha \\Delta t}{h^2} \\left( T_{i+1,j}^n + T_{i-1,j}^n + T_{i,j+1}^n + T_{i,j-1}^n - 4T_{i,j}^n \\right),\n\\end{align}\n\nwhere the new condition for stability is\\begin{align}\n\\frac{\\alpha \\Delta t}{h^2} \\leq \\frac{1}{4}.\n\\end{align}","type":"content","url":"/lab2#extension-to-two-dimensions","position":19},{"hierarchy":{"lvl1":"Lab 2 - The Heat Diffusion Equation - Finite Difference","lvl2":"Simulation Details"},"type":"lvl2","url":"/lab2#simulation-details","position":20},{"hierarchy":{"lvl1":"Lab 2 - The Heat Diffusion Equation - Finite Difference","lvl2":"Simulation Details"},"content":"You will simulate heat diffusion along a rod of length L.\n\nDiscretise the rod into N spatial points.\n\nChoose a time step \\Delta t satisfying the stability condition.\n\nApply boundary conditions (e.g., fixed temperature at both ends).\n\nEvolve the temperature distribution over time.","type":"content","url":"/lab2#simulation-details","position":21},{"hierarchy":{"lvl1":"Lab 2 - The Heat Diffusion Equation - Finite Difference","lvl3":"Physical Interpretation","lvl2":"Simulation Details"},"type":"lvl3","url":"/lab2#physical-interpretation","position":22},{"hierarchy":{"lvl1":"Lab 2 - The Heat Diffusion Equation - Finite Difference","lvl3":"Physical Interpretation","lvl2":"Simulation Details"},"content":"Heat flows from regions of high temperature to low temperature. The finite difference method allows us to approximate this process numerically. Over time, sharp temperature gradients smooth out, and the system approaches thermal equilibrium.\n\nThe rate of diffusion depends on the thermal diffusivity \\alpha. Larger values of \\alpha lead to faster smoothing of temperature differences.","type":"content","url":"/lab2#physical-interpretation","position":23},{"hierarchy":{"lvl1":"Lab 2 - The Heat Diffusion Equation - Finite Difference","lvl3":"Pseudo Code","lvl2":"Simulation Details"},"type":"lvl3","url":"/lab2#pseudo-code","position":24},{"hierarchy":{"lvl1":"Lab 2 - The Heat Diffusion Equation - Finite Difference","lvl3":"Pseudo Code","lvl2":"Simulation Details"},"content":"Algorithm\n\nHeat Diffusion Simulation (1D Finite Difference)\n\nInitialisation\n\nDefine rod length L and number of spatial points N.\n\nDefine thermal diffusivity \\alpha.\n\nChoose spatial step size \\Delta x = L/(N-1).\n\nChoose time step \\Delta t such that\nr = \\frac{\\alpha \\Delta t}{(\\Delta x)^2} \\le \\frac{1}{2}.\n\nInitialise temperature vector T with chosen initial condition.\n\nApply boundary conditions.\n\nTime Evolution\n\nFor each time step n:\n\nFor each interior point i = 2, \\dots, N-1:\\begin{align}\n   T_i^{n+1}\n   =\n   T_i^n\n   +\n   r \\left( T_{i+1}^n - 2T_i^n + T_{i-1}^n \\right)\n   \\end{align}\n\nApply boundary conditions to T^{n+1}.\n\nStore temperature profile if required.\n\nPlot temperature profile at chosen intervals.","type":"content","url":"/lab2#pseudo-code","position":25},{"hierarchy":{"lvl1":"Lab 2 - The Heat Diffusion Equation - Finite Difference","lvl2":"Target Results"},"type":"lvl2","url":"/lab2#target-results","position":26},{"hierarchy":{"lvl1":"Lab 2 - The Heat Diffusion Equation - Finite Difference","lvl2":"Target Results"},"content":"\n\nFigure 3:Example solution in one dimension.\n\nYou should observe:\n\nHeat diffusing smoothly along the rod.\n\nTemperature gradients decreasing with time.\n\nStability when r \\le 1/2.\n\nInstability when the stability condition is violated.","type":"content","url":"/lab2#target-results","position":27},{"hierarchy":{"lvl1":"Lab 2 - The Heat Diffusion Equation - Finite Difference","lvl2":"Further Investigation"},"type":"lvl2","url":"/lab2#further-investigation","position":28},{"hierarchy":{"lvl1":"Lab 2 - The Heat Diffusion Equation - Finite Difference","lvl2":"Further Investigation"},"content":"Explore different initial temperature distributions.\n\nInvestigate what happens when the stability condition is violated.\n\nCompare numerical results with analytical solutions (if available).\n\nExtend the simulation to two dimensions.","type":"content","url":"/lab2#further-investigation","position":29},{"hierarchy":{"lvl1":"Lab 3 - The Heat Diffusion Equation - Fourier Transform"},"type":"lvl1","url":"/lab3","position":0},{"hierarchy":{"lvl1":"Lab 3 - The Heat Diffusion Equation - Fourier Transform"},"content":"","type":"content","url":"/lab3","position":1},{"hierarchy":{"lvl1":"Lab 3 - The Heat Diffusion Equation - Fourier Transform","lvl2":"Overview"},"type":"lvl2","url":"/lab3#overview","position":2},{"hierarchy":{"lvl1":"Lab 3 - The Heat Diffusion Equation - Fourier Transform","lvl2":"Overview"},"content":"In this lab, we will solve the heat diffusion equation via a Fourier-based method, representing the conduction of heat through a solid as time evolves. The simulation will show how a system with an initial localised area of heat will transition to a system where the heat is distributed throughout space.  We will start by initialising an array that represents where the heat in a sample is and then use the Fourier method to solve the equation and update the spatial distribution of heat as time evolves.  We find that the heat distribution at time t+\\Delta t is equal to the inverse Fourier transform of the Fourier transform of the current heat distribution multiplied by a Gaussian function.  In the Fourier domain, the multiplication by the Gaussian attenuates the high spatial frequency components of the temperature distribution.\n\nThis simulation is an example of using a Fourier-based approach for solving a second-order partial differential equation.  As with the finite difference method, a similar approach can be used to solve many other similar differential equations.","type":"content","url":"/lab3#overview","position":3},{"hierarchy":{"lvl1":"Lab 3 - The Heat Diffusion Equation - Fourier Transform","lvl3":"Learning Outcomes","lvl2":"Overview"},"type":"lvl3","url":"/lab3#learning-outcomes","position":4},{"hierarchy":{"lvl1":"Lab 3 - The Heat Diffusion Equation - Fourier Transform","lvl3":"Learning Outcomes","lvl2":"Overview"},"content":"By the end of this lab you should be able to:\n\nUnderstand the physical principles behind thermal diffusion.\n\nLearn how to numerically solve the one-dimensional heat equation using Fourier-based methods.\n\nImplement the method in MATLAB and analyze the temperature evolution in a solid.\n\nUnderstand the extension of the method to two and three dimensions.\n\nUnderstand the extension of the method to include the addition of heat sources.\n\nUnderstand the advantages and disadvantages of this method versus the finite difference approach","type":"content","url":"/lab3#learning-outcomes","position":5},{"hierarchy":{"lvl1":"Lab 3 - The Heat Diffusion Equation - Fourier Transform","lvl2":"Background"},"type":"lvl2","url":"/lab3#background","position":6},{"hierarchy":{"lvl1":"Lab 3 - The Heat Diffusion Equation - Fourier Transform","lvl2":"Background"},"content":"","type":"content","url":"/lab3#background","position":7},{"hierarchy":{"lvl1":"Lab 3 - The Heat Diffusion Equation - Fourier Transform","lvl3":"Exponential Decay and Newton’s Law of Cooling","lvl2":"Background"},"type":"lvl3","url":"/lab3#exponential-decay-and-newtons-law-of-cooling","position":8},{"hierarchy":{"lvl1":"Lab 3 - The Heat Diffusion Equation - Fourier Transform","lvl3":"Exponential Decay and Newton’s Law of Cooling","lvl2":"Background"},"content":"Before solving the heat equation, it’s helpful to understand a simpler example of exponential decay, which is Newton’s Law of Cooling. This describes the temperature ( T(t) ) of an object as it cools in a surrounding environment of constant temperature ( T_{\\text{env}} ). The rate of cooling is proportional to the temperature difference\\frac{dT}{dt} = -\\kappa(T - T_{\\text{env}}),\n\nwhere ( \\kappa > 0 ) is a cooling constant.","type":"content","url":"/lab3#exponential-decay-and-newtons-law-of-cooling","position":9},{"hierarchy":{"lvl1":"Lab 3 - The Heat Diffusion Equation - Fourier Transform","lvl3":"Solution","lvl2":"Background"},"type":"lvl3","url":"/lab3#solution","position":10},{"hierarchy":{"lvl1":"Lab 3 - The Heat Diffusion Equation - Fourier Transform","lvl3":"Solution","lvl2":"Background"},"content":"We can solve this first-order ODE by separating variables\n\n[\n\\frac{dT}{T - T_{\\text{env}}} = -\\kappa,dt.\n]\n\nIntegrating both sides we get\n\n[\n\\ln|T - T_{\\text{env}}| = -\\kappa t + C\n\\quad \\Rightarrow \\quad\nT(t) = T_{\\text{env}} + (T_0 - T_{\\text{env}}) e^{-\\kappa t}.\n]\n\nThis shows that the temperature approaches the environment temperature exponentially over time.  It is important to note that to find the temperature at any future time, we only need to know the initial conditions (T_0 and T_{\\text{env}}) and the time t.","type":"content","url":"/lab3#solution","position":11},{"hierarchy":{"lvl1":"Lab 3 - The Heat Diffusion Equation - Fourier Transform","lvl3":"connection to the Heat Equation","lvl2":"Background"},"type":"lvl3","url":"/lab3#connection-to-the-heat-equation","position":12},{"hierarchy":{"lvl1":"Lab 3 - The Heat Diffusion Equation - Fourier Transform","lvl3":"connection to the Heat Equation","lvl2":"Background"},"content":"This solution is of the same form as the solution to the Fourier-transformed heat equation (Equation 4 in this document), where each Fourier mode decays exponentially in time:\n\n[\n\\hat{T}(k,t) = \\hat{T}(k,0) e^{-\\alpha k^2 t}\n]\n\nUnderstanding Newton’s Law of Cooling helps recognise exponential decay in thermal processes, and see how the system relaxes toward equilibrium over time.","type":"content","url":"/lab3#connection-to-the-heat-equation","position":13},{"hierarchy":{"lvl1":"Lab 1 — Entropy Mixing"},"type":"lvl1","url":"/lab4","position":0},{"hierarchy":{"lvl1":"Lab 1 — Entropy Mixing"},"content":"","type":"content","url":"/lab4","position":1},{"hierarchy":{"lvl1":"Lab 1 — Entropy Mixing","lvl2":"Thermal Physics Lab 1 — Entropy Increase Due to Convection and Conduction"},"type":"lvl2","url":"/lab4#thermal-physics-lab-1-entropy-increase-due-to-convection-and-conduction","position":2},{"hierarchy":{"lvl1":"Lab 1 — Entropy Mixing","lvl2":"Thermal Physics Lab 1 — Entropy Increase Due to Convection and Conduction"},"content":"Physics, Heriot-Watt University","type":"content","url":"/lab4#thermal-physics-lab-1-entropy-increase-due-to-convection-and-conduction","position":3},{"hierarchy":{"lvl1":"Lab 1 — Entropy Mixing","lvl3":"Overview","lvl2":"Thermal Physics Lab 1 — Entropy Increase Due to Convection and Conduction"},"type":"lvl3","url":"/lab4#overview","position":4},{"hierarchy":{"lvl1":"Lab 1 — Entropy Mixing","lvl3":"Overview","lvl2":"Thermal Physics Lab 1 — Entropy Increase Due to Convection and Conduction"},"content":"In this lab, we will create a simulation designed to illustrate the concept of entropy increase through either convection or conduction. The simulation will show how a system with several hot particles separated from cold particles evolves as the particles mix and exchange energy.  We will start by initialising an array of N particles with the hot particles originally separated from the cold particles.  As time evolves, neighbouring particles can either swap positions, representing convection, or they can exchange energy, representing conduction.  We find that the entropy increases with time, reflecting a loss of spatial information about where the hot particles are.  This is an example of the second law of thermodynamics, which states that the entropy of a closed system will increase or remain constant with time.\n\nThis simulation is an example of predictable macroscopic behaviour emerging from simple rules of microscopic states.  We can make some simple assumptions about how two neighbouring particles might interact with each other, and then observe how these influence the properties of the combined system.\n\nIn this case, we the only update rule that we apply is that neighbouring particles can either swap locations (simulating convection) or exchange and average their energies (simulating conduction).  These simple rules then result in a predictable increase in entropy associated with the location of the heat in a system.  An important outcome is that we can be confident of the long-term behaviour of the system (increase in entropy), but we cannot predict what will happen in any one time step (the entropy may go up or down).","type":"content","url":"/lab4#overview","position":5},{"hierarchy":{"lvl1":"Lab 1 — Entropy Mixing","lvl3":"Learning Outcomes","lvl2":"Thermal Physics Lab 1 — Entropy Increase Due to Convection and Conduction"},"type":"lvl3","url":"/lab4#learning-outcomes","position":6},{"hierarchy":{"lvl1":"Lab 1 — Entropy Mixing","lvl3":"Learning Outcomes","lvl2":"Thermal Physics Lab 1 — Entropy Increase Due to Convection and Conduction"},"content":"By the end of this lab you should be able to:\n\nSimulate convection and/or conduction of heat via simple update rules.\n\nDescribe entropy as a measure of spatial distribution of energy.\n\nUnderstand that small fluctuations can temporarily reduce entropy.\n\nExplain how microscopic randomness produces predictable macroscopic behaviour.","type":"content","url":"/lab4#learning-outcomes","position":7},{"hierarchy":{"lvl1":"Lab 1 — Entropy Mixing","lvl2":"Background"},"type":"lvl2","url":"/lab4#background","position":8},{"hierarchy":{"lvl1":"Lab 1 — Entropy Mixing","lvl2":"Background"},"content":"","type":"content","url":"/lab4#background","position":9},{"hierarchy":{"lvl1":"Lab 1 — Entropy Mixing","lvl3":"Shannon Entropy","lvl2":"Background"},"type":"lvl3","url":"/lab4#shannon-entropy","position":10},{"hierarchy":{"lvl1":"Lab 1 — Entropy Mixing","lvl3":"Shannon Entropy","lvl2":"Background"},"content":"The Shannon entropy isS = -\\sum_i p_i \\log_2 p_i\n\nwhere p_i is the probability of a random event occurring.\n\nUsing \\log_2 gives entropy in bits.","type":"content","url":"/lab4#shannon-entropy","position":11},{"hierarchy":{"lvl1":"Lab 1 — Entropy Mixing","lvl3":"Gibbs and Boltzmann Entropy","lvl2":"Background"},"type":"lvl3","url":"/lab4#gibbs-and-boltzmann-entropy","position":12},{"hierarchy":{"lvl1":"Lab 1 — Entropy Mixing","lvl3":"Gibbs and Boltzmann Entropy","lvl2":"Background"},"content":"In statistical mechanics,S = -k_B \\sum_i p_i \\ln p_i\n\nIf all microstates are equally probable, p_i = 1/\\Omega, givingS = k_B \\ln \\Omega.\n\nIf \\Omega = 1, then S = 0.","type":"content","url":"/lab4#gibbs-and-boltzmann-entropy","position":13},{"hierarchy":{"lvl1":"Lab 1 — Entropy Mixing","lvl3":"Second Law of Thermodynamics","lvl2":"Background"},"type":"lvl3","url":"/lab4#second-law-of-thermodynamics","position":14},{"hierarchy":{"lvl1":"Lab 1 — Entropy Mixing","lvl3":"Second Law of Thermodynamics","lvl2":"Background"},"content":"For an isolated system,\\Delta S_{\\text{total}} \\ge 0.\n\nEntropy increases until equilibrium is reached.","type":"content","url":"/lab4#second-law-of-thermodynamics","position":15},{"hierarchy":{"lvl1":"Lab 1 — Entropy Mixing","lvl3":"Convection vs Conduction","lvl2":"Background"},"type":"lvl3","url":"/lab4#convection-vs-conduction","position":16},{"hierarchy":{"lvl1":"Lab 1 — Entropy Mixing","lvl3":"Convection vs Conduction","lvl2":"Background"},"content":"Convection → swap neighbouring particles.\n\nConduction → average neighbouring energies.","type":"content","url":"/lab4#convection-vs-conduction","position":17},{"hierarchy":{"lvl1":"Lab 1 — Entropy Mixing","lvl2":"Simulation Details"},"type":"lvl2","url":"/lab4#simulation-details","position":18},{"hierarchy":{"lvl1":"Lab 1 — Entropy Mixing","lvl2":"Simulation Details"},"content":"\n\nSchematic illustration of entropy increase during mixing.","type":"content","url":"/lab4#simulation-details","position":19},{"hierarchy":{"lvl1":""},"type":"lvl1","url":"/lite-coin-entropy","position":0},{"hierarchy":{"lvl1":""},"content":"# Imports\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Try to enable widgets (works if ipywidgets is available in your JupyterLite build)\ntry:\n    import ipywidgets as widgets\n    from IPython.display import display\n    WIDGETS_AVAILABLE = True\nexcept Exception as e:\n    WIDGETS_AVAILABLE = False\n    print(\"ipywidgets not available in this environment. Use the Manual mode cell below.\")\n\n\n\n\ndef shannon_entropy_bits(p: float) -> float:\n    \"\"\"Shannon entropy of a Bernoulli(p) variable in bits.\"\"\"\n    # Protect against log(0)\n    eps = 1e-12\n    p = float(np.clip(p, eps, 1 - eps))\n    q = 1 - p\n    return -(p * np.log2(p) + q * np.log2(q))\n\ndef effective_modes(p: float) -> float:\n    \"\"\"Effective number of outcomes (a.k.a. 'effective modes')\"\"\"\n    return 2 ** shannon_entropy_bits(p)\n\ndef make_plots(p: float) -> None:\n    \"\"\"Create the three-panel visualization inspired by the lab figure.\"\"\"\n    p = float(np.clip(p, 0.0, 1.0))\n    q = 1 - p\n    H = shannon_entropy_bits(p)\n    Neff = 2 ** H\n\n    # Curves\n    ps = np.linspace(0, 1, 600)\n    Hs = np.array([shannon_entropy_bits(x) for x in ps])\n    Ns = 2 ** Hs\n\n    fig = plt.figure(figsize=(11, 7.2))\n    gs = fig.add_gridspec(2, 2, height_ratios=[1, 0.95], hspace=0.55, wspace=0.35)\n\n    ax1 = fig.add_subplot(gs[0, 0])\n    ax2 = fig.add_subplot(gs[0, 1])\n    ax3 = fig.add_subplot(gs[1, :])\n\n    # Plot entropy vs p\n    ax1.plot(ps, Hs, linewidth=1.5)\n    ax1.set_xlabel(\"Probability of getting heads, p\")\n    ax1.set_ylabel(\"Entropy H(p) [bits]\")\n    ax1.set_xlim(0, 1)\n    ax1.set_ylim(0, 1.05)\n    ax1.grid(True, alpha=0.25)\n    ax1.scatter([p], [H], s=40, zorder=3)\n\n    # Plot effective modes vs p\n    ax2.plot(ps, Ns, linewidth=1.5)\n    ax2.set_xlabel(\"Probability of getting heads, p\")\n    ax2.set_ylabel(\"Effective number of modes, $2^{H(p)}$\")\n    ax2.set_xlim(0, 1)\n    ax2.set_ylim(0.9, 2.1)\n    ax2.grid(True, alpha=0.25)\n    ax2.scatter([p], [Neff], s=40, zorder=3)\n\n    # Bar chart for (Heads, Tails)\n    ax3.bar([\"Heads\", \"Tails\"], [p, q])\n    ax3.set_ylim(0, 1.05)\n    ax3.set_ylabel(\"Probability\")\n    ax3.grid(True, axis='y', alpha=0.25)\n\n    # Big summary text (inspired by your figure)\n    summary = f\"Entropy H = {H:.3f} bits, effective modes = {Neff:.3f}\"\n    fig.suptitle(summary, fontsize=18, y=0.98)\n\n    # Extra annotation for extremes\n    if p < 1e-6 or (1 - p) < 1e-6:\n        ax3.text(0.5, -0.22, \"Fully predictable outcome → H = 0, modes = 1\",\n                 transform=ax3.transAxes, ha='center', va='top', fontsize=13)\n    elif abs(p - 0.5) < 1e-3:\n        ax3.text(0.5, -0.22, \"Fair coin → maximum uncertainty → H = 1, modes = 2\",\n                 transform=ax3.transAxes, ha='center', va='top', fontsize=13)\n\n    plt.show()\n\n\n\n\nif WIDGETS_AVAILABLE:\n    p_slider = widgets.FloatSlider(\n        value=0.5,\n        min=0.0,\n        max=1.0,\n        step=0.001,\n        description='p',\n        readout_format='.3f',\n        continuous_update=True,\n        style={'description_width': 'initial'},\n        layout=widgets.Layout(width='520px')\n    )\n\n    ui = widgets.VBox([\n        widgets.HTML(\"<b>Adjust the coin bias</b>: p = P(Heads)\"),\n        p_slider\n    ])\n\n    out = widgets.interactive_output(make_plots, {'p': p_slider})\n    display(ui, out)\nelse:\n    print(\"Widgets not available. Run the 'Manual mode' cell below.\")\n\n\n\n\n","type":"content","url":"/lite-coin-entropy","position":1}]}